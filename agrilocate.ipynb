{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14648547,"sourceType":"datasetVersion","datasetId":9357638}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset (CSV file path you download from Kaggle)\ndf = pd.read_csv(\"/kaggle/input/forecasting/CropDataset-Enhanced.csv\")\n\n# Display columns to confirm names\nprint(\"All columns in dataset:\\n\", df.columns)\n\n# Select only required columns\ncols_to_keep = [\n    \"Address\",\n    \"Formatted address\",\n    \"Longitude\",\n    \"Location Type\",\n    \"Crop\"\n]\n\n# Filter the dataset\ndf_clean = df[cols_to_keep]\n\n# Save cleaned data\ndf_clean.to_csv(\"geo_crop_cleaned.csv\", index=False)\n\nprint(\"Cleaned dataset saved to geo_crop_cleaned.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T09:18:48.829402Z","iopub.execute_input":"2026-01-28T09:18:48.830293Z","iopub.status.idle":"2026-01-28T09:18:48.856151Z","shell.execute_reply.started":"2026-01-28T09:18:48.830260Z","shell.execute_reply":"2026-01-28T09:18:48.854784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# -----------------------------\n# Load cleaned dataset\n# -----------------------------\ndf = pd.read_csv(\"geo_crop_cleaned.csv\")\n\n# Keep only required columns\ndf = df[[\"Address\", \"Crop\"]]\n\n# Drop missing values\ndf.dropna(inplace=True)\n\n# -----------------------------\n# Encode Crop labels\n# -----------------------------\nlabel_encoder = LabelEncoder()\ndf[\"Crop\"] = label_encoder.fit_transform(df[\"Crop\"])\n\nnum_classes = len(label_encoder.classes_)\nprint(\"Number of crop classes:\", num_classes)\n\n# -----------------------------\n# Train-test split\n# -----------------------------\nX_train, X_test, y_train, y_test = train_test_split(\n    df[\"Address\"],\n    df[\"Crop\"],\n    test_size=0.2,\n    random_state=42\n)\n\n# -----------------------------\n# Text Vectorization\n# -----------------------------\nmax_tokens = 10000\nsequence_length = 50\n\nvectorizer = tf.keras.layers.TextVectorization(\n    max_tokens=max_tokens,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length\n)\n\nvectorizer.adapt(X_train)\n\n# -----------------------------\n# TensorFlow Dataset\n# -----------------------------\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntest_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n\ntrain_ds = train_ds.batch(32).prefetch(tf.data.AUTOTUNE)\ntest_ds = test_ds.batch(32).prefetch(tf.data.AUTOTUNE)\n\n# -----------------------------\n# Model Definition\n# -----------------------------\nmodel = tf.keras.Sequential([\n    vectorizer,\n    tf.keras.layers.Embedding(max_tokens, 64),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(64, activation=\"relu\"),\n    tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n])\n\n# -----------------------------\n# Compile Model\n# -----------------------------\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\n# -----------------------------\n# Train Model\n# -----------------------------\nmodel.fit(\n    train_ds,\n    validation_data=test_ds,\n    epochs=10\n)\n\n# -----------------------------\n# Save Model (FIXED)\n# -----------------------------\nmodel.save(\"address_to_crop_model.keras\")\n\nprint(\"Model saved successfully!\")\n\n# -----------------------------\n# Prediction Function\n# -----------------------------\ndef predict_crop(address):\n    # Wrap the string in a tf.constant\n    prediction = model.predict(tf.constant([address]))\n    crop_index = prediction.argmax(axis=1)[0]\n    return label_encoder.inverse_transform([crop_index])[0]\n\n\n# -----------------------------\n# Example Prediction\n# -----------------------------\nsample_address = \"Village near Pune Maharashtra\"\npredicted_crop = predict_crop(sample_address)\n\nprint(\"Predicted Crop:\", predicted_crop)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T09:25:07.316140Z","iopub.execute_input":"2026-01-28T09:25:07.316670Z","iopub.status.idle":"2026-01-28T09:25:11.131841Z","shell.execute_reply.started":"2026-01-28T09:25:07.316636Z","shell.execute_reply":"2026-01-28T09:25:11.129902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load cleaned dataset\ndf = pd.read_csv(\"geo_crop_cleaned.csv\")\n\n# Keep only required columns\ndf = df[[\"Address\", \"Crop\"]]\n\n# Drop missing values\ndf.dropna(inplace=True)\n\n# Function to get crop(s) for an input address\ndef get_crop_by_address(address):\n    # Filter dataset for matching addresses (case-insensitive, contains)\n    matched = df[df[\"Address\"].str.lower().str.contains(address.lower())]\n    \n    if matched.empty:\n        return f\"Address: {address}\\nCrop(s): Not found in dataset\"\n    \n    # Return all unique crops for that address\n    crops = matched[\"Crop\"].unique()\n    crops_str = \", \".join(crops)\n    \n    return f\"Address: {address}\\nCrop(s): {crops_str}\"\n\n# Example usage for Amravati\nsample_address = \"Amravati\"\nresult = get_crop_by_address(sample_address)\n\nprint(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T09:29:10.679873Z","iopub.execute_input":"2026-01-28T09:29:10.680265Z","iopub.status.idle":"2026-01-28T09:29:10.698781Z","shell.execute_reply.started":"2026-01-28T09:29:10.680238Z","shell.execute_reply":"2026-01-28T09:29:10.697497Z"}},"outputs":[],"execution_count":null}]}